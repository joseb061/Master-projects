---
title: "Exercise set 1"
author: "Joseba Hernandez Bravo and Jorge Vicente Puig"
date: "17/12/2021"
output:
  rmdformats::downcute:
    self_contained: true
    thumbnails: true
    lightbox: true
    gallery: false
    highlight: tango
---

```{r, message = FALSE}
library(combinat)
```

# TASK 1

In this first task we will examine the correlation between the pairs of (X1,Y1)
values by means of a correlation test. 

We will perform and exact test for $H_{0}:\rho=0$ against $H_{1}:\rho>0$ where:

- $H_{0}:\rho=0$: There is no correlation between Chest circumference and volume of air

- $H_{1}:\rho>0$: Chest circumference and volume of air are positively correlated

## Pearson

Firstly we will perform the test using a Pearson correlation coefficient


```{r}
x= c(39,29,60,40,32)
y=c(11,5,20,8,6)

sttrue= cor(x,y, method = "pearson")

n=length(y)
nr=fact(n) #number of rearrangements to be examined
st=numeric(nr)

cnt=0
d=permn(y)

for (i in 1:nr){
  st[i]<-cor(d[[i]],x)
  if (st[i] >=sttrue)
    cnt=cnt+1
}
```

```{r}
print(paste("p-value= ",cnt/nr))
```
```{r}
hist(st)
abline(v=sttrue,col="blue",lwd=2)
```

As the p values is less than$0.05$ we will reject the null
hypothesis. So, we can say that there is sufficient evidence to conclude that the 
relationship between X an Y could be linear.$H_{0}:\rho > 0$ 


## Spearman

We will now follow the same strategy but using Spearman's correlation
coefficient instead of Pearson's. 

```{r}
x= c(39,29,60,40,32)
y=c(11,5,20,8,6)

sttrue= cor(x,y, method = "spearman")

n=length(y)
nr=fact(n) #number of rearrangements to be examined
st=numeric(nr)

cnt=0
d=permn(y)

for (i in 1:nr){
  st[i]<-cor(d[[i]],x)
  if (st[i] >=sttrue)
    cnt=cnt+1
}
```

```{r}
print(paste("p-value= ",cnt/nr))
```

```{r}
hist(st)
abline(v=sttrue,col="blue",lwd=2)
```

In this case the p-value $= 0.066$ which is slightly greater than $ 0.05$ . Therefore, we can conclude that $H_{0}$ is likely and that we cannot reject it.
So we can not say that X and Y are correlated in this case. 

# TASK 2



# TASK 3

The first thing we will do is to create a Data frame with the following variables: "TEMP" (Temperature), "TMG" (Time mowing the grass) and "WC" (Water Consumption). Then, we will use the function "lm" in R to build a model that predicts the variance of "WC" as a function of the other two previously defined variables. So,

```{r}
df<-data.frame(TEMP = c(75,83,85,85,92,97,99),
           WC = c(16,20,25,27,32,48,48),
           TMG=c(1.85,1.25,1.5,1.75,1.15,1.75,1.6))


model <- lm(WC ~ TEMP+TMG,data=df)
summary(model)
```
As we can see, both p-values for the variables *TEMP* and  *TMG* have a values lower than 0.05. Therefore, we can conclude that both variables are significant in explaining the variation of *WC*. However, if we compare these two values we can see that in the case of *TEMP* the value is $~188$ times lower. This means that despite having two significant variables, one will have more weight than the other. 

On the other hand, if we look at the coefficients of the regression we can see that the values of *TEMP* are multiplied by $1.512$ while those of *TMG* are multiplied by $12.531$. It may seem strange that the coefficient of the variable *TEMP* is lower than that of *TMG*. However, it should be noted that the mean of *TEMP* is approximately $56$ times higher than that of *TMG*.

Once we have obtain the results from the model we will compare de p-values using the correlation test. 

```{r}
# CORRELATION TEST

x=df$TEMP
y=df$WC

sttrue= cor(x,y)

n=length(y)
nr=fact(n) #number of rearrangements to be examined
st=numeric(nr)

cnt=0
d=permn(y)

for (i in 1:nr){
  st[i]<-cor(d[[i]],x)
  if (st[i] >=sttrue)
    cnt=cnt+1
}
```
```{r}
print(paste("p-value= ",cnt/nr))
```

```{r}

library(combinat)
x=df$TMG
y=df$WC

sttrue= cor(x,y)

n=length(y)
nr=fact(n) #number of rearrangements to be examined
st=numeric(nr)

cnt=0
d=permn(y)

for (i in 1:nr){
  st[i]<-cor(d[[i]],x)
  if (st[i] >=sttrue)
    cnt=cnt+1
}

```
```{r}
print(paste("p-value= ",cnt/nr))
```

As we can observe in the case of the variable *TMG*, the p-value is greater than 0.05. Therefore, we cannot discard the null hypothesis (there is no correlation between *TMG* and *WC*). In other words, we cannot say that there is a correlation between these two variables. 

On the other hand, the variable "TEMP" does present a p-value lower than 0.05. Therefore, we can discard the null hypothesis and we can state that there is a correlation between the two variables.  


